{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Science with Python ](./fig/Data_Science_WVCTSI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmuak2ODsbfH"
   },
   "source": [
    "# Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OycGAL0hsbfK"
   },
   "source": [
    "Scikit-learn is a software machine learning library for the Python programming language. It features:\n",
    "\n",
    "* various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means, density-based spatial clustering of applications with noise (DBSCAN), etc.\n",
    "* dimension reduction, feature extraction, normalization, etc.\n",
    "\n",
    "Scikit-learn is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy. Note that scikit-learn doesn't support GPU yet.\n",
    "\n",
    "![sklearn](https://github.com/happidence1/AILabs/blob/master/images/sklearn.svg?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkM4eAwVsbfL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UGpgQI8sbfM"
   },
   "source": [
    "## 1. Linear Regression \n",
    "Linear Regression is a statistical technique for estimating the relationships among variables and predicting a continuous-valued attribute associated with an object.\n",
    "Linear Regression fits a linear model with coefficients  to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "atSZ4nTcsbfM",
    "outputId": "51112374-73b8-4cab-d220-0fcc79f4459f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a data set\n",
    "n_samples = 20\n",
    "x = np.linspace(-1.5, 2.0, n_samples)[:, np.newaxis]\n",
    "y = 3 * x + 2 + 0.5*np.random.randn(n_samples, 1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZpNGUlqsbfN",
    "outputId": "8aff7363-9455-4f79-b9e0-a4456d18a422"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTP6VDPvsbfN",
    "outputId": "077435f1-83f4-4f31-cd11-641161fc30c3"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l3oxJdJssbfO"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "# Fit linear model.\n",
    "model.fit(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vxj1LGTCsbfO",
    "outputId": "888057ba-5c8a-4c09-f8bc-3f726899eb28"
   },
   "outputs": [],
   "source": [
    "# Estimated coefficients for the linear regression problem. \n",
    "# If multiple targets are passed during the fit (y 2D), \n",
    "# this is a 2D array of shape (n_targets, n_features), while \n",
    "# if only one target is passed, this is a 1D array of length n_features.\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyGsuygfsbfP",
    "outputId": "d334760c-520b-4027-d569-46339f60d3c3"
   },
   "outputs": [],
   "source": [
    "# Independent term in the linear model.\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQbGVyXVsbfP",
    "outputId": "1e53bf40-d81a-4740-96f7-2c34048cf350"
   },
   "outputs": [],
   "source": [
    "# Returns the coefficient of determination R^2 of the prediction.\n",
    "model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "I22o7BNOsbfQ",
    "outputId": "19bbc679-0fb6-4633-d935-24ffafc2c10b"
   },
   "outputs": [],
   "source": [
    "# Plot the data and the model prediction\n",
    "y_fit = model.predict(x)\n",
    "\n",
    "# plot the original data set\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# plot the bestfit line\n",
    "plt.plot(x, y_fit, color='r');\n",
    "\n",
    "# output text on the figure\n",
    "plt.text(-1.5, 6, r\"Y = %f *x + %f\"%(model.coef_, model.intercept_), fontsize=15, color='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQjVV-9EsbfQ"
   },
   "outputs": [],
   "source": [
    "# let's try polynomial fitting with the linear regression\n",
    "x = np.linspace(-1.5, 2.0, n_samples)[:, np.newaxis]\n",
    "y = 3 * x**4 + 2.5*x**2 + 4.7 * x + np.random.randn(n_samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "NuLQ0_U3sbfR",
    "outputId": "98f7f663-0a43-46e1-dab6-c6713bbd8190"
   },
   "outputs": [],
   "source": [
    "x_poly = np.hstack([x, x**2, x**3, x**4])\n",
    "model.fit(x_poly, y);\n",
    "print(model.coef_)\n",
    "y_pred = model.predict(x_poly)\n",
    "plt.scatter(x, y);\n",
    "plt.plot(x, y_pred, 'r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ukjsw60msbfR",
    "outputId": "5e5da0ae-7a23-4219-f3a0-a029b470f019"
   },
   "outputs": [],
   "source": [
    "x_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-atnlXWsbfR",
    "outputId": "69f80dd1-5953-4a29-9bdb-2276986bdbfc"
   },
   "outputs": [],
   "source": [
    "help(np.hstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSHsb10QsbfS"
   },
   "source": [
    "## 2. Classification\n",
    "Classification is to Identify to which category an object belongs to based on a training set of data containing observations (or instances) whose category membership is known.\n",
    "\n",
    "Another way to think of classification is as a discrete form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXJ-QkbDsbfS"
   },
   "source": [
    "### 2.1 Classificaiton - SVM\n",
    "Support-vector machines (SVMs), are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. \n",
    "\n",
    "The primary task of an SVM algorithm is to find the vector/hyperplane that separates binary sets with the maximum margin to both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "zkc81XtbsbfS",
    "outputId": "cbe4a5fa-6151-431d-89c8-c212c7c06a25"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "n_samples = 500\n",
    "x, y = make_blobs(n_samples=n_samples, centers=2,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y, s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeTE8q2bsbfT"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(x, y);\n",
    "w=clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "jn4U8SZFsbfT",
    "outputId": "8c595b7c-4264-44fa-afe8-9638a0ca0924"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1], c=y, s=50);\n",
    "a = -w[0] / w[1]\n",
    "b = (clf.intercept_[0]) / w[1]\n",
    "x_fit  = np.linspace(-1, 4)\n",
    "plt.plot(x_fit, a * x_fit - b)\n",
    "plt.text(-1, -1, r\"Y = %f *x + %f\"%(a, b), fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m_aZbCwsbfT"
   },
   "source": [
    "### 2.2 Classificaiton - KNN Classifier\n",
    "The K-Nearest Neighbors (KNN) algorithm is a method used for algorithm used for classification or for regression. In both cases, the input consists of the k closest training examples in the feature space. Given a new, unknown observation, look up which points have the closest features and assign the predominant class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "I3OicgtasbfT",
    "outputId": "a58f2ee2-9a4b-4b0d-b05d-68701199bcb5"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "x, y = make_blobs(n_samples=n_samples, centers=4,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "colours = ['green', 'blue', 'purple', 'orange']\n",
    "plt.scatter(x[:, 0], x[:, 1], c=[colours[i] for i in y], s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbVJ5yLusbfU"
   },
   "outputs": [],
   "source": [
    "# create the model \n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
    "\n",
    "# fit the model with the blobs generated above.\n",
    "knn.fit(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "_IsrYW0QsbfU",
    "outputId": "97df5326-e62e-4725-8a02-307423d81661"
   },
   "outputs": [],
   "source": [
    "x_pred = [1, 6]\n",
    "# r = knn.predict([x_pred,])\n",
    "r = knn.predict([x_pred])\n",
    "# plt.scatter(x[:, 0], x[:, 1], c=(y==r[0]));\n",
    "plt.scatter(x[:, 0], x[:, 1], c=[colours[i] for i in y], s=50);\n",
    "# plt.scatter(x_pred[0], x_pred[1], c='red', s=50);\n",
    "plt.scatter(x_pred[0], x_pred[1], c=colours[r[0]], marker='*', s=200);\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VBHZbYrsbfU"
   },
   "source": [
    "## 3. Clustering\n",
    "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\n",
    "\n",
    "Common clustering algorithms include K-means, Density-based spatial clustering of applications with noise (DBSCAN) and mean-shift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "cz9VCl-asbfU",
    "outputId": "aeead5c1-5608-4fdb-9629-af3bd04057aa"
   },
   "outputs": [],
   "source": [
    "# We will use the blobs crated above for clustering examples as well.\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBOWk_-tsbfU"
   },
   "source": [
    "### 3.1 Clustering - K-Means\n",
    "The K-Means algorithm searches for a predetermined number of clusters within an unlabeled multidimensional dataset.\n",
    "The \"cluster center\" is the arithmetic mean of all the points belonging to the cluster.\n",
    "Each point is closer to its own cluster center than to other cluster centers. K-Means clustering highly depends on the K clusters that is specified at the beginning. It works best when the number of clusters is known. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_a7IJTDmsbfU",
    "outputId": "f42c25c6-8d42-4ae3-f8a4-0ab5951f3dcf"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "x, y = make_blobs(n_samples=n_samples, centers=4,\n",
    "                  random_state=0, cluster_std=1.0)\n",
    "y_pred = KMeans(n_clusters=4).fit(x)\n",
    "y_pred.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "-NFfSoh0sbfV",
    "outputId": "ac437340-2ca3-40de-dbb0-f70e76ed5e4e"
   },
   "outputs": [],
   "source": [
    "# original classification\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y);\n",
    "plt.scatter(y_pred.cluster_centers_[:, 0], y_pred.cluster_centers_[:, 1], c='r', s=80);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "N2Q5FyS5sbfV",
    "outputId": "1061fa8e-4018-4c33-c735-3f4f119f3183"
   },
   "outputs": [],
   "source": [
    "# predicted clustering\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_pred.predict(x));\n",
    "plt.scatter(y_pred.cluster_centers_[:, 0], y_pred.cluster_centers_[:, 1], c='r', s=80);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnVlXwqdsbfV"
   },
   "source": [
    "## 4. Additional Materials - Principal component analysis (PCA)\n",
    "Principal component analysis (PCA) is a statistical procedure that converts a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. PCA is mostly used as a tool in exploratory data analysis and for making predictive models.\n",
    "\n",
    "We will explore the Iris Data set again with scikit-learn, which contains a clean copy of the Iris data set.\n",
    "\n",
    "This data sets consists of 3 different types of irisesâ€™ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
    "\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "The below plot uses the first two features. See [here](https://en.wikipedia.org/wiki/Iris_flower_data_set) for more information on this dataset.\n",
    "\n",
    "![petal_sepal](https://github.com/happidence1/AILabs/blob/master/images/petal_sepal.jpg?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biM8o1-6sbfV"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "OakYy7ItsbfV",
    "outputId": "85081a75-677e-4db5-a7b8-1de5f35ca1a1"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYRY2iyAsbfW",
    "outputId": "cf0918ca-b686-45a8-da02-c44c58863705"
   },
   "outputs": [],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "LmL64oLWsbfW",
    "outputId": "78cf3c19-dd87-43b5-cd8e-ff12051479f5"
   },
   "outputs": [],
   "source": [
    "iris_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "OYwM9ZwysbfW",
    "outputId": "f5c3692e-c50c-4246-c5f8-2af558d7f4bf"
   },
   "outputs": [],
   "source": [
    "iris_df.corr().style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "3y9a0yuEsbfW",
    "outputId": "237a73a7-b3bd-4d86-a20d-23799233bb2c"
   },
   "outputs": [],
   "source": [
    "iris_df['target'].value_counts().plot.pie(explode=[0.1,0.1,0.1],autopct='%1.1f%%',shadow=True,figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "94ZLjSPcsbfW",
    "outputId": "8b0cc8ba-384c-49dd-cdca-a5f0dab487d2"
   },
   "outputs": [],
   "source": [
    "colours = ['red', 'orange', 'blue']\n",
    "species = ['I. setosa', 'I. versicolor', 'I. virginica']\n",
    "\n",
    "# iterate through 3 species\n",
    "for i in range(0, 3):    \n",
    "    species_df = iris_df[iris_df['target'] == i]    \n",
    "    plt.scatter(species_df['sepal length (cm)'],        \n",
    "        species_df['sepal width (cm)'],\n",
    "        color=colours[i],        \n",
    "        alpha=0.5,        \n",
    "        label=species[i],\n",
    "    )\n",
    "plt.xlabel('sepal length (cm)');\n",
    "plt.ylabel('sepal width (cm)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBX6iVumsbfW",
    "outputId": "e0f1e91f-6295-455f-8a9a-4acbe035bd43"
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = iris.data.shape\n",
    "\n",
    "print(iris.keys())\n",
    "print((n_samples, n_features))\n",
    "print(iris.data.shape)\n",
    "print(iris.target.shape)\n",
    "print(iris.target_names)\n",
    "print(iris.feature_names)\n",
    "x, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sU4Fvr8cwDU5",
    "outputId": "c08190b8-d5a2-4ccc-cdfc-74d6d9fcef9e"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JLTAntZsbfX"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "z6dlnbWAsbfX",
    "outputId": "b536d969-72f0-485d-abfa-4874340729c9"
   },
   "outputs": [],
   "source": [
    "print(\"Reduced dataset shape:\", x_pca.shape)\n",
    "plt.scatter(x_pca[:, 0], x_pca[:, 1], c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3));\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "\n",
    "print(\"Meaning of the 2 components:\")\n",
    "for component in pca.components_:\n",
    "    print(\" + \".join(\"%.3f x %s\" % (value, name)\n",
    "                     for value, name in zip(component,\n",
    "                                            iris.feature_names)))\n",
    "for length, vector in zip(pca.explained_variance_ratio_, pca.components_):\n",
    "    v = vector * 10 * np.sqrt(length)\n",
    "    plt.plot([0, v[0]], [0, v[1]], '-k', lw=3)  \n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrWY3w2xsbfX",
    "outputId": "8a87128a-db86-4494-d6a5-bf9b8e220e21"
   },
   "outputs": [],
   "source": [
    "# variance ratio of the components\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5frT_DJsbfX",
    "outputId": "2b318d9a-57f5-4048-c794-a47241933dab"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hN1DTTo6sbfX",
    "outputId": "f27309f0-84a4-4b45-9938-5bb027a19ed6"
   },
   "outputs": [],
   "source": [
    "x_pca.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "03_machine_learning_sklearn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
