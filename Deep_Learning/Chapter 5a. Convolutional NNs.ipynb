{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fcb6fb1",
   "metadata": {},
   "source": [
    "![Deep Learning for Scientists in a hurry](./fig/Title.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f87b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d452871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "chapter_number = 5\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a1d17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe964859",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (Concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2cd7c0",
   "metadata": {},
   "source": [
    "The neural networks that we have seen so were built from layers densely connected in sequence. \n",
    "\n",
    "We used in a previous chapter a dense NN capable of classifying hand-written digits. We did that by flattening the bitmap into a vector and using several layers. There are two limitations to this approach. \n",
    "\n",
    "1. An image is a 2D array of pixels and the natural connection of those pixels is lost when we flatten the array. We would like to preserve the fact that an image is a 2D array and pixels have other neighbors \n",
    "\n",
    "2. From another side, there is translational invariance on an image, for example, you can move a digit a few pixels to the right and the image should be equally recognizable. However, from the point of view of a dense Neural Network that corresponds to a very different input. \n",
    "\n",
    "\n",
    "Convolutional Neural networks were found to be a very good solution to those limitations.\n",
    "\n",
    "In this notebook, we will describe CNN's without using any particular DL engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e3ad5",
   "metadata": {},
   "source": [
    "## Convolutional Neural networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8155d6",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks is an specialized kind of NN for data that has some sort of grid-like topology.\n",
    "By grid-like topology, we understand some sort of contiguity between the values of the input.\n",
    "\n",
    "For example, we can think about time-series data as a one-dimensional grid with values sampled at regular intervals. An image is logically a 2D grid and a video could be considered a 3D grid of data. \n",
    "\n",
    "The name \" convolutional network\" implies that the network uses something inspired by a mathematical operation called **convolution**.\n",
    "This is a special kind of linear operation that will replace the matrix multiplication that we used for dense neural networks.\n",
    "\n",
    "There is another operation that is used in convolutional networks and it is called **pooling**. Pooling is no other thing that a reduction of dimensionality by applying a certain mathematical operation to patches of the grid.\n",
    "\n",
    "*Convolutional neural networks are simply neural networks that use **convolution** in at least one of their layers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a358b",
   "metadata": {},
   "source": [
    "### The mathematical convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da7512",
   "metadata": {},
   "source": [
    "In mathematics, a convolution is an operation on two functions. In one dimension you can express a convolution with this equation:\n",
    "\n",
    "$$s(t) = (f * g)(t) := \\int f(a) g(t-a) da$$\n",
    "\n",
    "A **convolution** is defined as the integral of the product of the two functions after one is reversed and shifted. The integral is evaluated for all values of shift, producing what is also called the **convolution function**.\n",
    "\n",
    "Let's explore this definition with a simple numerical example:\n",
    "We start with two functions on two NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301542cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x < -1 or x > 1:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    if x<-1 or x > 1:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1.0 - (x+1)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83df2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-2,2,0.01)\n",
    "f_vec = np.vectorize(f)\n",
    "g_vec = np.vectorize(g)\n",
    "f_arr=f_vec(x)\n",
    "g_arr=g_vec(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fa4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, f_arr, label=r\"$f(x)$\")\n",
    "plt.plot(x, g_arr, label=r\"$g(x)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1f9e0",
   "metadata": {},
   "source": [
    "These two functions are particularly suited for convolutions because their product will vanish for most points except on a restricted range. \n",
    "\n",
    "As we need to compute an integral, ie the area under the product of these two functions let's do that here with the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5673276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(t):\n",
    "    ret = 0.0\n",
    "    delta = 0.01\n",
    "    for x in np.arange(-10,10,delta):\n",
    "        ret += f(x)*g(t-x)*delta\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cadf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_vec = np.vectorize(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_conv = np.arange(-3,3,0.01)\n",
    "conv_arr=conv_vec(x_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_conv, conv_arr, label=r\"$(f * g)(t)$\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536c4f9",
   "metadata": {},
   "source": [
    "Convolution has applications in many areas of science including probability, statistics, acoustics, spectroscopy, signal processing, image processing, geophysics, engineering, physics, computer vision, and differential equations.\n",
    "\n",
    "What is important to keep in mind is that on a convolution there is the displacement of a function over another, the product of the resulting overlapping and a final sum. This is in essence what we use as convolution, now with a grid of values instead of real-valued functions.\n",
    "\n",
    "In machine learning the function $f(x)$ is replaced by a grid of values, the entire image for example, and the function $g(x)$ will be a grid of weights, the values that will be optimized by the neural network.\n",
    "\n",
    "In the case of images, for example. we use a two-dimensional image I as the input and the weights form another grid K called the **kernel**. In this case, the convolution is defined as:\n",
    "\n",
    "$$S(i,j) = (I*K)(i,j) = \\sum_m \\sum_n I(m, n) K(i-m,j-n)$$\n",
    "\n",
    "In general $(f*g)(t) \\neq (g*f)(t)$ except for symmetric functions. However, in this particular case, we can swap the two grids and the result will be the same, ie:\n",
    "\n",
    "$$S(i,j) = (K*I)(i,j) = \\sum_m \\sum_n I(i-m, j-n) K(m,n)$$\n",
    "\n",
    "In practice what many neural network engines implement is a related function called the **cross-correlation** which is the same as a convolution but without the flipping of the kernel. The point is that the definition of the kernel could be considered as the grid of values that are used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8baa6d",
   "metadata": {},
   "source": [
    "### Example of 2-D convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91749e8",
   "metadata": {},
   "source": [
    "To clarify the role of convolutions for Neural Networks let's present two views. One from the symbolic point of view and another from a numerical example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73119b17",
   "metadata": {},
   "source": [
    "![Convolution](./fig/convolution.svg)\n",
    "\n",
    "The first element:\n",
    "\n",
    "![Convolution](./fig/convolution11.svg)\n",
    "\n",
    "The last element:\n",
    "\n",
    "![Convolution](./fig/convolution23.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6667f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "There are many books about Deep Learning and many more on Machine Learning. \n",
    "This list is by no means an exhaustive list of books. I am listing the books from which I took inspiration. Also, I am listing materials where I found better ways to present topics. Often I am amazed by how people can create approachable materials for seemingly dry subjects.\n",
    "\n",
    "The order of the books goes from divulgation and practical to the more rigorous and mathematical. Slides, blogs, and videos are those I have found over the internet or suggested by others.\n",
    "\n",
    "### Selection of Books on Deep Learning\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Kelleher\" \n",
    "       src=\"./fig/books/Deep Learning - Kelleher.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      John D. Kelleher<br>\n",
    "      2019<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Charniak\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Charniak.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Eugene Charniak<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Skansi\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Skansi.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Sandro Skansi<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Subramanian\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Subramanian.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Vishnu Subramanian<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Stevens\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Stevens.png\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Eli Stevens, Luca Artiga and Thomas Viehmann<br>\n",
    "      2020<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with Python - Chollet\" \n",
    "       src=\"./fig/books/Deep Learning with Python - Chollet.jpg\" \n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with Python (Second Edition)<br>\n",
    "      Fran√ßois Chollet<br>\n",
    "      2021<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Patterson\" \n",
    "       src=\"./fig/books/Deep Learning - Patterson.jpeg\"\n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning, a practitioner's approach<br>\n",
    "      Josh Patterson and Adam Gibson<br>\n",
    "      2017<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Goodfellow\" \n",
    "       src=\"./fig/books/Deep Learning - Goodfellow.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      Ian Goodfellow, Yoshua Bengio, and Aaron Courville<br>\n",
    "      2016<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Interactive Books\n",
    "\n",
    "  * [Dive into Deep Learning](https://d2l.ai/index.html)<br>\n",
    "    Interactive deep learning book with code, math, and discussions<br> \n",
    "    Implemented with PyTorch, NumPy/MXNet, and TensorFlow<br>\n",
    "    Adopted at 300 universities from 55 countries\n",
    "\n",
    "\n",
    "### Slides\n",
    "\n",
    "  * John Urbanic's [\"Deep Learning in one Afternoon\"](https://www.psc.edu/wp-content/uploads/2022/04/Deep-Learning.pdf)<br>\n",
    "An excellent fast, condensed introduction to Deep Learning.<br>\n",
    "John is a Parallel Computing Scientist at Pittsburgh Supercomputing Center\n",
    "\n",
    "  * [Christopher Olah's Blog](http://colah.github.io) is very good. For example about [Back Propagation](http://colah.github.io/posts/2015-08-Backprop)\n",
    "\n",
    "  * Adam W. Harley on his CMU page offers [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://www.cs.cmu.edu/~aharley/vis/)\n",
    "\n",
    "\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    " * [Yale Digital Humanities Lab](https://github.com/YaleDHLab/lab-workshops)\n",
    " \n",
    " * Aurelien Geron Hands-on Machine Learning with Scikit-learn \n",
    "   [First Edition](https://github.com/ageron/handson-ml) and\n",
    "   [Second Edition](https://github.com/ageron/handson-ml2)\n",
    "   \n",
    " * [A progressive collection notebooks of the Machine Learning course by the University of Turin](https://github.com/rugantio/MachineLearningCourse)\n",
    "   \n",
    " * [A curated set of jupyter notebooks about many topics](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "   \n",
    "### Videos\n",
    "\n",
    " * [Caltech's \"Learning from Data\" by Professor Yaser Abu-Mostafa](https://work.caltech.edu/telecourse.html)\n",
    " \n",
    " * [3Blue1Brown Youtube Channel](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01932d",
   "metadata": {},
   "source": [
    "# Back of the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1ab97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = chapter_number\n",
    "t = np.linspace(0, (2*(n-1)+1)*np.pi/2, 1000)\n",
    "x = t*np.cos(t)**3\n",
    "y = 9*t*np.sqrt(np.abs(np.cos(t))) + t*np.sin(0.3*t)*np.cos(2*t)\n",
    "plt.plot(x, y, c=\"green\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00659ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'Chapter {chapter_number} took {int(end - start):d} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
