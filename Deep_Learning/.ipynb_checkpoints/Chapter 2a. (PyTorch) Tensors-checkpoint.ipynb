{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deep Learning for Scientists in a hurry](./fig/Title.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-09-01T12:55:46.647674-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.6\n",
      "IPython version      : 8.2.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.30)\n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "chapter_number = 2\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy     : 1.23.1\n",
      "torch     : 1.12.0\n",
      "matplotlib: 3.5.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that Python offers a few [Sequence Types](https://docs.python.org/3/library/stdtypes.html#typesseq). \n",
    "There are three basic sequence types: lists, tuples, and range objects.\n",
    "Python itself is not a particularly fast programming language and using those sequence types does not help when dealing with large amounts of numbers as we will typically find on Deep Learning applications.\n",
    "\n",
    "The reason why we can still consider Python an excellent language for Scientific Computing is that we can avoid using list and tuples and delegate the hard work of numerical manipulations to specialized libraries such as NumPy.\n",
    "\n",
    "We learn in Python Programming that we can create lists and tuples as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [1,2,3,4]\n",
    "b_tupl = (7,8,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists are mutable, ie you can add or remove elements while a tuple is unmutable, you can only add elements by creating a new tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list.append(5)\n",
    "a_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also learn from our lesson on NumPy that this library offers a convenient object called, `ndarray` that can store multidimensional arrays. We can for example use the list and tuple above to create NumPy arrays from them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_np = np.array(a_list)\n",
    "a_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_np = np.array(b_tupl)\n",
    "b_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python lists and tuples are collections of Python objects that are allocated individually in memory. There is no promise of contiguity and as an object, they use more memory than the simple storage of their value.\n",
    "\n",
    "NumPy arrays on the other hand are views over (typically) contiguous portions of memory and they contained unboxed C numeric types instead of Python objects.\n",
    "\n",
    "NumPy arrays seem like the ideal objects in Python for Deep Learning, except for being limited to allocate the arrays in CPU RAM.\n",
    "\n",
    "One of the reasons for the success of Deep Learning is the availability of powerful accelerators such Graphic Processing Units (GPUs). A GPU has its RAM and can only process data that is allocated there. We need an object that is capable of working with Arrays stored in CPU RAM as well as GPU RAM. The solution in PyTorch is to create its data type called **PyTorch tensors**.\n",
    "\n",
    "In this notebook, we will learn what we need to know for working with **PyTorch Tensors** but first let's check if we are working on a machine where a GPU is present and available for working with PyTorch. We will concentrate our discussion on NVIDIA GPUs the most common accelerators which are widely supported by PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the presence of a CUDA device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to check if a GPU is present in the machine and CUDA capable. For NVIDIA GPUs we can execute the command `nvidia-smi` from a terminal. Inside a jupyter notebook, we can achieve the same by prefixing commands with an exclamation mark (`!`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option from inside PyTorch is wiht the command `torch.cuda.is_available()`.\n",
    "This is a small recipe for identifying if we can work with the GPU on PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several tensor constructors. Similar to those in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a constructor for uninitialized variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -1.5846e+29, -3.5394e-12,  2.5250e-29,  1.8028e+28],\n",
       "        [ 4.6114e+24,  4.7851e+22,  3.1096e-18,  2.7254e+20,  9.3168e-39],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.empty(5,5)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values contain the remanents of the data in the locations of memory where the object is created.\n",
    "\n",
    "A Tensor with random values in its entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0076, 0.3449, 0.2861],\n",
       "        [0.3971, 0.6360, 0.3176],\n",
       "        [0.2730, 0.9297, 0.8267]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 7, 4],\n",
       "        [1, 0, 3],\n",
       "        [1, 5, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0,9,(3,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Numpy, new tensor can be created from lists and lists of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1400, 1.6700])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3.14, 1.67])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider for example having a tensor for storing the X and Y coordinates of a triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  0.,  1.,  1., -1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([-1.0, -1.0, 0.0, 1.0, 1.0, -1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position of the first point would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, -1.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unidimensional array works but it will not be ideal. In this case, a 2-D array is a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[-1.0, -1.0], [0.0, 1.0], [1.0, -1.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensors have a `shape` the number of values on each dimension. In mathematical terminology is the *order of a tensor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another element that shares familiarity with NumPy is the `dtype`. Consider for example this array of integers where we are explicitly saying that we will use 8 bits per value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]], dtype=torch.int8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor(range(16), dtype=torch.int8).reshape(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New arrays can be created with the same dtype from another tensor. Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 0],\n",
       "        [0, 0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.new_empty((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [2, 2]], dtype=torch.int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.new_full((2,2),2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]], dtype=torch.int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.new_ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.new_zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]], dtype=torch.int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensor dtype is very similar to the NumPy dtype. Here is the list\n",
    "\n",
    "| Name | Description |\n",
    "|:--|:--:|\n",
    "|`torch.float32` or `torch.float` | Single precision floating point number |\n",
    "|`torch.float64` or `torch.double` | Double precision floating point number |\n",
    "|`torch.float16` or `torch.half` | Half precision floating point number |\n",
    "|`torch.int8`  | 8-bit integer with signed |\n",
    "|`torch.uint8`  | 8-bit integer unsigned |\n",
    "|`torch.int16`  | 16-bit integer with sign |\n",
    "|`torch.int32`  | 32-bit integer with sign |\n",
    "|`torch.int64`  | 64-bit integer with sign |\n",
    "|`torch.bool`  | Boolean |\n",
    "\n",
    "The default type for tensors is `torch.float`\n",
    "\n",
    "We can find the type with the `dtype` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of creating copies of a tensor with a declared dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd = x.double()\n",
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to(dtype=torch.half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tensor Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of tensors are allocated in contiguous chunks in memory and they are managed by `torch.Storage` instances.\n",
    "\n",
    "Multiple tensors can index the same storage in different ways. That offers a powerful tool to manipulate multidimensional arrays without the overhead of having to copy the data to a different location each time we change the way or portion of data that we want to access. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]], dtype=torch.int8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576652848"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       "[torch.storage._TypedStorage(dtype=torch.int8, device=cpu) of size 16]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In place operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change values of a tensor explicitly element by element or we can use functions that will operate over an entire tensor. Operations that act over the tensor instead of creating a new one have the underscore suffix (`_`).\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4768, 0.4613, 0.7798, 0.4502],\n",
       "        [0.3329, 0.6372, 0.4861, 0.8882],\n",
       "        [0.2301, 0.9201, 0.0680, 0.4982]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.zero_()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1400, 3.1400, 3.1400, 3.1400],\n",
       "        [3.1400, 3.1400, 3.1400, 3.1400],\n",
       "        [3.1400, 3.1400, 3.1400, 3.1400]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fill_(3.14)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a tensor (Size, Offset and Stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(11,17,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12],\n",
       "        [13, 14],\n",
       "        [15, 16]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the storage for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 6]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the python location in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576808288"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 elements that determine how elements from x will be returned from the two indexes used for this 2-D tensor. They are the `shape`, `stride` and `offset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/Tensor_Shape_Stride.png\" width=400 height=60  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 13, 15],\n",
       "        [12, 14, 16]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = x.transpose(0,1)\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An let's see how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 6]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/Tensor_Shape_Stride_Trans.png\" width=400 height=60  >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider another example with a view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13],\n",
       "        [14, 15, 16],\n",
       "        [17, 18, 19]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(11,20).reshape(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13],\n",
       "        [17, 18, 19]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a[::2]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 9]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider this other example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 16],\n",
       "        [18, 19]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a[1:,1:]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 9]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contigous tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some operations with PyTorch tensors only operate with contiguous tensors. We can ask for the contiguity using the method `is_contiguous`. Tensors can become contiguous with the method `.contiguous()`. The method preserves the content but will change the storage and stride, it is a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 16],\n",
       "        [18, 19]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=c.contiguous()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 15\n",
       " 16\n",
       " 18\n",
       " 19\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 4]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider these tensors with random entries from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3372, 0.4874, 0.1386],\n",
      "        [0.3513, 0.3229, 0.0637]])\n",
      "tensor([[0.9704, 0.6633, 0.6434],\n",
      "        [0.1298, 0.4312, 0.6329]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand((2,3))\n",
    "print(x)\n",
    "y=torch.rand((2,3))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to do element-wise operations such as the sum. Using the overloaded operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3076, 1.1507, 0.7820],\n",
       "        [0.4811, 0.7541, 0.6966]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the class method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3076, 1.1507, 0.7820],\n",
       "        [0.4811, 0.7541, 0.6966]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3076, 1.1507, 0.7820],\n",
       "        [0.4811, 0.7541, 0.6966]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=torch.empty((2,3))\n",
    "torch.add(x,y, out=z)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the instance method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3076, 1.1507, 0.7820],\n",
       "        [0.4811, 0.7541, 0.6966]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instance method also includes an *in-place* version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3076, 1.1507, 0.7820],\n",
       "        [0.4811, 0.7541, 0.6966]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction into Python numbers and lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 12, 13, 14],\n",
       "        [15, 16, 17, 18]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(11,19).reshape(2,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x[1,2]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 12, 13, 14], [15, 16, 17, 18]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Tensors {to, from} Numpy Arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor(range(36)).reshape(6,6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x.numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[999,   1,   2,   3,   4,   5],\n",
       "       [  6,   7,   8,   9,  10,  11],\n",
       "       [ 12,  13,  14,  15,  16,  17],\n",
       "       [ 18,  19,  20,  21,  22,  23],\n",
       "       [ 24,  25,  26,  27,  28,  29],\n",
       "       [ 30,  31,  32,  33,  34,  35]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]=999\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion from Numpy to Torch preserving memory addressing is also possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96188153, 0.56784203, 0.25352348],\n",
       "       [0.10043693, 0.7271248 , 0.91652376],\n",
       "       [0.98135794, 0.12622719, 0.32199153]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn=np.random.rand(3,3)\n",
    "xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9619, 0.5678, 0.2535],\n",
       "        [0.1004, 0.7271, 0.9165],\n",
       "        [0.9814, 0.1262, 0.3220]], dtype=torch.float64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt=torch.from_numpy(xn)\n",
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.        ,   0.56784203,   0.25352348],\n",
       "       [  0.10043693,   0.7271248 ,   0.91652376],\n",
       "       [  0.98135794,   0.12622719,   0.32199153]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt[0,0]=100\n",
    "xn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving tensors to the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mention before, one of the biggest motivations for creating a new data type instead of using NumPy is the need for storing arrays on accelerators such as NVIDIA GPUs.\n",
    "\n",
    "Every PyTorch tensor can be transferred to one of the GPUs to perform fast computations there.\n",
    "\n",
    "Operations on the GPU will be executed using GPU-specific operations.\n",
    "\n",
    "The operations in this section only work if this notebook is running on a machine with GPU access.\n",
    "To preserve the executability of this notebook we are adding a conditional in case this notebook is running on a machine without one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x_gpu = torch.tensor([3.14, 1.67], device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x_gpu = x.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be moved from the CPU to the GPU and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x_gpu = x.cuda()\n",
    "    x_cpu = x_gpu.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways of storing tensors. Storing large amounts of numerical data in text format is a bad idea.\n",
    "\n",
    "Here we will explore two alternatives to export tensors efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dedicated serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x,'./output/torch_x.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('./output/torch_x.t')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./output/torch_x.h5'):\n",
    "    os.remove('./output/torch_x.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to a HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = h5py.File('./output/torch_x.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = wf.create_dataset('my_tensor', data=x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('./output/torch_x.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = f['my_tensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(dset[:])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd: Automatic gradient evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more advance topic that is very particular for PyTorch for the purpose of be use for Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.1400, 4.1400, 4.1400],\n",
      "        [4.1400, 4.1400, 4.1400],\n",
      "        [4.1400, 4.1400, 4.1400]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 3.14\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x1329be4a0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[212.8739, 212.8739, 212.8739],\n",
      "        [212.8739, 212.8739, 212.8739],\n",
      "        [212.8739, 212.8739, 212.8739]], grad_fn=<MulBackward0>) tensor(212.8739, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y**2 * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property of being tracked for gradient computation can be enable after the object is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x1329be7d0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.1396, 17.1396, 17.1396],\n",
       "        [17.1396, 17.1396, 17.1396],\n",
       "        [17.1396, 17.1396, 17.1396]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "   1. Create a tensor with the first 10 odd numbers. Use for example lists comprehension or a `torch.arange` or even `numpy.arange`.\n",
    "   \n",
    "      a. Predict the shape, the offset, stride. Test your ideas by inspecting the actual values from them.\n",
    "      \n",
    "      b. Can you transpose this tensor? Can you find a way of doing it?\n",
    "      \n",
    "      c. Change the shape to get the tensor with 2 rows.\n",
    "      \n",
    "      d. Create another view where you remove the zero. Check that your new tensor now has 9 elements.\n",
    "      \n",
    "      e. For the tensor in (d) reshape it to a 3x3 tensor.\n",
    "      \n",
    "   2. Consider the tensor\n",
    "   \n",
    "      `x = torch.arange(27).reshape(3,3,3)`\n",
    "      \n",
    "      a. What is the view that will return `tensor([ 4, 13, 22])`\n",
    "      \n",
    "      b. Create a view that return the 8 corners of the tensor\n",
    "         The 8 corners are `[[[0, 2], [6, 8]], [[18, 20], [24, 26]]]`\n",
    "         \n",
    "      c. Create the tensor `x[1:,2:,-1]`. Predict and then check the size. offset and stride.\n",
    "      \n",
    "   3. Import the module `math` from the standard library.\n",
    "   \n",
    "      a. Try to apply for example `math.exp()` to the whole tensor.\n",
    "      \n",
    "      b. Can you find the function on pytorch library?\n",
    "      \n",
    "      c. Apply the function using the pytorch function.\n",
    "      \n",
    "   4. Check if you can use a GPU.\n",
    "   \n",
    "      a. Move the tensor x to the GPU\n",
    "      \n",
    "      b. Execute the operation on the GPU\n",
    "      \n",
    "      c. Return the resulting tensor to the CPU.\n",
    "      \n",
    "   5. Remember the sofmax function:\n",
    "   \n",
    "   $$\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\ \\ \\ \\ \\text{ for } i = 1, \\dotsc , K \\text{ and } \\mathbf z=(z_1,\\dotsc,z_K) \\in\\mathbb{R}^K.$$\n",
    "\n",
    "      a. Create a 1-D random tensor with 100 elements\n",
    "      \n",
    "      b. Compute the softmax of the random tensor. Search for the methods that allow you to perform the task without using loops.\n",
    "      \n",
    "      c. Take the first element of the tensor and change it for a large value such as $999$ and the last element for a negative value such as $-999$.\n",
    "      \n",
    "      d. Compute again the softmax\n",
    "      \n",
    "      e. Create a slice with the fist and last value of the softmax result\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "There are many books about Deep Learning and many more on Machine Learning. \n",
    "This list is by no means an exhaustive list of books. I am listing the books from which I took inspiration. Also, I am listing materials where I found better ways to present topics. Often I am amazed by how people can create approachable materials for seemingly dry subjects.\n",
    "\n",
    "The order of the books goes from divulgation and practical to the more rigorous and mathematical. Slides, blogs, and videos are those I have found over the internet or suggested by others.\n",
    "\n",
    "### Selection of Books on Deep Learning\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Kelleher\" \n",
    "       src=\"./fig/books/Deep Learning - Kelleher.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      John D. Kelleher<br>\n",
    "      2019<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Charniak\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Charniak.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Eugene Charniak<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Skansi\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Skansi.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Sandro Skansi<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Subramanian\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Subramanian.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Vishnu Subramanian<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Stevens\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Stevens.png\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Eli Stevens, Luca Artiga and Thomas Viehmann<br>\n",
    "      2020<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with Python - Chollet\" \n",
    "       src=\"./fig/books/Deep Learning with Python - Chollet.jpg\" \n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with Python (Second Edition)<br>\n",
    "      François Chollet<br>\n",
    "      2021<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Patterson\" \n",
    "       src=\"./fig/books/Deep Learning - Patterson.jpeg\"\n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning, a practitioner's approach<br>\n",
    "      Josh Patterson and Adam Gibson<br>\n",
    "      2017<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Goodfellow\" \n",
    "       src=\"./fig/books/Deep Learning - Goodfellow.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      Ian Goodfelow, Yoshua Bengio, and Aaron Courville<br>\n",
    "      2016<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Interactive Books\n",
    "\n",
    "  * [Dive into Deep Learning](https://d2l.ai/index.html)<br>\n",
    "    Interactive deep learning book with code, math, and discussions<br> \n",
    "    Implemented with PyTorch, NumPy/MXNet, and TensorFlow<br>\n",
    "    Adopted at 300 universities from 55 countries\n",
    "\n",
    "\n",
    "### Slides\n",
    "\n",
    "  * John Urbanic's [\"Deep Learning in one Afternoon\"](https://www.psc.edu/wp-content/uploads/2022/04/Deep-Learning.pdf)<br>\n",
    "An excellent fast, condensed introduction to Deep Learning.<br>\n",
    "John is a Parallel Computing Scientist at Pittsburgh Supercomputing Center\n",
    "\n",
    "  * [Christopher Olah's Blog](http://colah.github.io) is very good. For example about [Back Propagation](http://colah.github.io/posts/2015-08-Backprop)\n",
    "\n",
    "  * Adam W. Harley on his CMU page offers [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://www.cs.cmu.edu/~aharley/vis/)\n",
    "\n",
    "\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    " * [Yale Digital Humanities Lab](https://github.com/YaleDHLab/lab-workshops)\n",
    " \n",
    " * Aurelein Geron Hands-on Machine Learning with Scikit-learn \n",
    "   [First Edition](https://github.com/ageron/handson-ml) and\n",
    "   [Second Edition](https://github.com/ageron/handson-ml2)\n",
    "   \n",
    " * [A progressive collection notebooks of the Machine Learning course by the University of Turin](https://github.com/rugantio/MachineLearningCourse)\n",
    "   \n",
    " * [A curated set of jupyter notebooks about many topics](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "   \n",
    "### Videos\n",
    "\n",
    " * [Caltech's \"Learning from Data\" by Professor Yaser Abu-Mostafa](https://work.caltech.edu/telecourse.html)\n",
    " \n",
    " * [3Blue1Brown Youtube Channel](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back of the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = chapter_number\n",
    "t = np.linspace(0, (2*(n-1)+1)*np.pi/2, 1000)\n",
    "x = t*np.cos(t)**3\n",
    "y = 9*t*np.sqrt(np.abs(np.cos(t))) + t*np.sin(0.3*t)*np.cos(2*t)\n",
    "plt.plot(x, y, c=\"green\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 2 took 11 seconds\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'Chapter {chapter_number} took {int(end - start):d} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
