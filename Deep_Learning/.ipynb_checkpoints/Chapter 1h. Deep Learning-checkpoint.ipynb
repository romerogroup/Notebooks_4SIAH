{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Practical Machine Learning with Python\n",
    "# Chapter 11: Deep Learning\n",
    "## Guillermo Avendaño-Franco and Aldo Humberto Romero\n",
    "## West Virginia University\n",
    "\n",
    "### HPC Summer Workshop 2019\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on a variety of sources, usually other notebooks, the material was adapted to the topics covered during lessons. In some cases, the original notebooks were created for Python 2.x or older versions of Scikit-learn or Tensorflow and they have to be adapted. \n",
    "\n",
    "## References\n",
    "\n",
    "### Books\n",
    "\n",
    " * **Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems**, 1st Edition *Aurélien Géron*  (2017)\n",
    "\n",
    " * **Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow**, 2nd Edition, *Sebastian Raschka* and *Vahid Mirjalili* (2017)\n",
    "\n",
    " * **Deep Learning: A Practitioner's approach**, *Josh Patterson* and *Adam Gibson* \n",
    " \n",
    " * **Deep Learning**, *Ian Goodfelow*, *Yoshua Bengio* and *Aaron Courville* (2016)\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    " * [Yale Digital Humanities Lab](https://github.com/YaleDHLab/lab-workshops)\n",
    " \n",
    " * Aurelein Geron Hands-on Machine Learning with Scikit-learn \n",
    "   [First Edition](https://github.com/ageron/handson-ml)\n",
    "   [Second Edition (In preparation)](https://github.com/ageron/handson-ml2)\n",
    "   \n",
    " * [A progressive collection notebooks of the Machine Learning course by the University of Turin](https://github.com/rugantio/MachineLearningCourse)\n",
    "   \n",
    " * [A curated set of jupyter notebooks about many topics](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "   \n",
    "### Videos\n",
    "\n",
    " * [Caltech's \"Learning from Data\" by Professor Yaser Abu-Mostafa](https://work.caltech.edu/telecourse.html)\n",
    " \n",
    " The support of the National Science Foundation and the US Department of Energy under projects: DMREF-NSF 1434897, NSF OAC-1740111 and DOE DE-SC0016176 is recognized.\n",
    "\n",
    "<div style=\"clear: both; display: table;\">\n",
    "<div style=\"border: none; float: left; width: 40%; padding: 10px\">\n",
    "<img src=\"fig/NSF.jpg\" alt=\"National Science Foundation\" style=\"width:50%\" align=\"left\">\n",
    "    </div>\n",
    "    <div style=\"border: none; float: right; width: 40%; padding: 10px\">\n",
    "<img src=\"fig/DOE.jpg\" alt=\"National Science Foundation\" style=\"width:50%\" align=\"right\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This Jupyter notebook was created to run on a Python 3 kernel. Some Ipython magics were used: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands prefaced by a % in Jupyter are called \"magic\"\n",
    "# these \"magic\" commands allow us to do special things only related to jupyter\n",
    "\n",
    "# %matplotlib inline - allows one to display charts from the matplotlib library in a notebook\n",
    "# %load_ext autoreload - automatically reloads imported modules if they change\n",
    "# %autoreload 2 - automatically reloads imported modules if they change\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-08-17T20:41:38.212773-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.13\n",
      "IPython version      : 8.2.0\n",
      "\n",
      "Compiler    : Clang 11.0.3 (clang-1103.0.32.62)\n",
      "OS          : Darwin\n",
      "Release     : 19.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras     : 2.8.0\n",
      "tensorflow: 2.8.0\n",
      "matplotlib: 3.5.1\n",
      "pandas    : 1.2.4\n",
      "numpy     : 1.22.4\n",
      "scipy     : 1.8.1\n",
      "sklearn   : 1.1.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.2, 1.2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'ConstantV2',\n",
       " 'GlorotNormal',\n",
       " 'GlorotNormalV2',\n",
       " 'GlorotUniform',\n",
       " 'GlorotUniformV2',\n",
       " 'HeNormal',\n",
       " 'HeNormalV2',\n",
       " 'HeUniform',\n",
       " 'HeUniformV2',\n",
       " 'Identity',\n",
       " 'IdentityV2',\n",
       " 'Initializer',\n",
       " 'LOCAL',\n",
       " 'LecunNormal',\n",
       " 'LecunNormalV2',\n",
       " 'LecunUniform',\n",
       " 'LecunUniformV2',\n",
       " 'Ones',\n",
       " 'OnesV2',\n",
       " 'Orthogonal',\n",
       " 'OrthogonalV2',\n",
       " 'RandomNormal',\n",
       " 'RandomNormalV2',\n",
       " 'RandomUniform',\n",
       " 'RandomUniformV2',\n",
       " 'TruncatedNormal',\n",
       " 'TruncatedNormalV2',\n",
       " 'VarianceScaling',\n",
       " 'VarianceScalingV2',\n",
       " 'Zeros',\n",
       " 'ZerosV2',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'generic_utils',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_normalV2',\n",
       " 'glorot_uniform',\n",
       " 'glorot_uniformV2',\n",
       " 'he_normal',\n",
       " 'he_normalV2',\n",
       " 'he_uniform',\n",
       " 'he_uniformV2',\n",
       " 'identity',\n",
       " 'init_ops',\n",
       " 'initializer',\n",
       " 'initializers_v1',\n",
       " 'initializers_v2',\n",
       " 'inspect',\n",
       " 'keras_export',\n",
       " 'lecun_normal',\n",
       " 'lecun_normalV2',\n",
       " 'lecun_uniform',\n",
       " 'lecun_uniformV2',\n",
       " 'normal',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'populate_deserializable_objects',\n",
       " 'random_normal',\n",
       " 'random_uniform',\n",
       " 'serialize',\n",
       " 'tf',\n",
       " 'tf2',\n",
       " 'threading',\n",
       " 'truncated_normal',\n",
       " 'uniform',\n",
       " 'variance_scaling',\n",
       " 'zero',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x15ceb6fa0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x15ceb6070>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.5, 4.2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ELU',\n",
       " 'InputSpec',\n",
       " 'Layer',\n",
       " 'LeakyReLU',\n",
       " 'PReLU',\n",
       " 'ReLU',\n",
       " 'Softmax',\n",
       " 'ThresholdedReLU',\n",
       " 'advanced_activations',\n",
       " 'backend',\n",
       " 'constraints',\n",
       " 'deserialize',\n",
       " 'deserialize_keras_object',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'get_globals',\n",
       " 'hard_sigmoid',\n",
       " 'initializers',\n",
       " 'keras_export',\n",
       " 'leaky_relu',\n",
       " 'linear',\n",
       " 'log_softmax',\n",
       " 'regularizers',\n",
       " 'relu',\n",
       " 'relu6',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'serialize_keras_object',\n",
       " 'sigmoid',\n",
       " 'silu',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh',\n",
       " 'tf',\n",
       " 'tf_utils']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.random' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_random_seed\u001b[49m(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      5\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m]),\n\u001b[1;32m      6\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m300\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.random' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "tf.random.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try PReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SELU is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at what happens if we try to use the ReLU activation function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great at all, we suffered from the vanishing/exploding gradients problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's the final verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of almost 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 - 97.05) / (100 - 99.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule function can take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "#learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "#optimizer = keras.optimizers.SGD(learning_rate)\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=s, decay=0.1, nesterov=False)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For piecewise constant scheduling, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "#    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Cycle scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "#rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "#find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "#plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (iter2 - self.iteration)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "#                     for sample in range(100)])\n",
    "#y_proba = y_probas.mean(axis=0)\n",
    "#y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_std = y_probas.std(axis=0)\n",
    "#np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_model = keras.models.Sequential([\n",
    "#    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "#    for layer in model.layers\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "#mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
