{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e03a171",
   "metadata": {},
   "source": [
    "![Deep Learning for Scientists in a hurry](./fig/Title.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfd8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693ad292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-08-10T10:17:06.319147-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.13\n",
      "IPython version      : 8.3.0\n",
      "\n",
      "Compiler    : GCC 10.3.0\n",
      "OS          : Linux\n",
      "Release     : 3.10.0-1160.24.1.el7.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 24\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bca5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "start = time.time()\n",
    "chapter_number = 6\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36527e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a02f7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b933aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 10 10:17:38 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro P6000        Off  | 00000000:37:00.0 Off |                  Off |\r\n",
      "| 26%   22C    P0    57W / 250W |      2MiB / 24576MiB |      0%   E. Process |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de935cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib : 3.5.2\n",
      "torch      : 1.12.0a0+8a1a93a\n",
      "torchvision: 0.13.0a0\n",
      "numpy      : 1.22.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7467e6",
   "metadata": {},
   "source": [
    "# Deep Learning workflows with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c83ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841e925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee169d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0641, -0.0732, -0.1076,  0.1038, -0.0405,  0.0994, -0.0427, -0.0912,\n",
      "          0.1407, -0.0439]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171dd0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bbacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "597dce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6106, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4f5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x7fa95d66adc0>\n",
      "<AddmmBackward0 object at 0x7fa95d66ae50>\n",
      "<AccumulateGrad object at 0x7fa95d66adc0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7b2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0094, -0.0005, -0.0130,  0.0083, -0.0013,  0.0205])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431d603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727875da",
   "metadata": {},
   "source": [
    "# Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c3968f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4285a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d632707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca07bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad669a",
   "metadata": {},
   "source": [
    "# MNIST using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede73a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea109613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa95f856050>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(314259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902c15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8516bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cbc751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42b68494",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd8be75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 0.8430\n",
      "Current loss 0.5083\n",
      "Current loss 0.2276\n",
      "Current loss 0.2003\n",
      "Current loss 0.1345\n",
      "Current loss 0.1154\n",
      "Current loss 0.2713\n",
      "Current loss 0.1489\n",
      "Current loss 0.0815\n",
      "Current loss 0.4449\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Current loss {:.4f}'.format(float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17b48783",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './output/mnist/mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "526a86e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = Net()\n",
    "pretrained_model.load_state_dict(torch.load('./output/mnist/mnist.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b52d150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./output/mnist/mnist.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ef9da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "There are many books about Deep Learning and many more on Machine Learning. \n",
    "This list is by no means an exhaustive list of books. I am listing the books from which I took inspiration. Also, I am listing materials where I found better ways to present topics. Often I am amazed by how people can create approachable materials for seemingly dry subjects.\n",
    "\n",
    "The order of the books goes from divulgation and practical to the more rigorous and mathematical. Slides, blogs, and videos are those I have found over the internet or suggested by others.\n",
    "\n",
    "### Selection of Books on Deep Learning\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Kelleher\" \n",
    "       src=\"./fig/books/Deep Learning - Kelleher.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      John D. Kelleher<br>\n",
    "      2019<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Charniak\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Charniak.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Eugene Charniak<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Skansi\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Skansi.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Sandro Skansi<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Subramanian\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Subramanian.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Vishnu Subramanian<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Stevens\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Stevens.png\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Eli Stevens, Luca Artiga and Thomas Viehmann<br>\n",
    "      2020<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with Python - Chollet\" \n",
    "       src=\"./fig/books/Deep Learning with Python - Chollet.jpg\" \n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with Python (Second Edition)<br>\n",
    "      François Chollet<br>\n",
    "      2021<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Patterson\" \n",
    "       src=\"./fig/books/Deep Learning - Patterson.jpeg\"\n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning, a practitioner's approach<br>\n",
    "      Josh Patterson and Adam Gibson<br>\n",
    "      2017<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Goodfellow\" \n",
    "       src=\"./fig/books/Deep Learning - Goodfellow.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      Ian Goodfellow, Yoshua Bengio, and Aaron Courville<br>\n",
    "      2016<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Interactive Books\n",
    "\n",
    "  * [Dive into Deep Learning](https://d2l.ai/index.html)<br>\n",
    "    Interactive deep learning book with code, math, and discussions<br> \n",
    "    Implemented with PyTorch, NumPy/MXNet, and TensorFlow<br>\n",
    "    Adopted at 300 universities from 55 countries\n",
    "\n",
    "\n",
    "### Slides\n",
    "\n",
    "  * John Urbanic's [\"Deep Learning in one Afternoon\"](https://www.psc.edu/wp-content/uploads/2022/04/Deep-Learning.pdf)<br>\n",
    "An excellent fast, condensed introduction to Deep Learning.<br>\n",
    "John is a Parallel Computing Scientist at Pittsburgh Supercomputing Center\n",
    "\n",
    "  * [Christopher Olah's Blog](http://colah.github.io) is very good. For example about [Back Propagation](http://colah.github.io/posts/2015-08-Backprop)\n",
    "\n",
    "  * Adam W. Harley on his CMU page offers [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://www.cs.cmu.edu/~aharley/vis/)\n",
    "\n",
    "\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    " * [Yale Digital Humanities Lab](https://github.com/YaleDHLab/lab-workshops)\n",
    " \n",
    " * Aurelien Geron Hands-on Machine Learning with Scikit-learn \n",
    "   [First Edition](https://github.com/ageron/handson-ml) and\n",
    "   [Second Edition](https://github.com/ageron/handson-ml2)\n",
    "   \n",
    " * [A progressive collection notebooks of the Machine Learning course by the University of Turin](https://github.com/rugantio/MachineLearningCourse)\n",
    "   \n",
    " * [A curated set of jupyter notebooks about many topics](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "   \n",
    "### Videos\n",
    "\n",
    " * [Caltech's \"Learning from Data\" by Professor Yaser Abu-Mostafa](https://work.caltech.edu/telecourse.html)\n",
    " \n",
    " * [3Blue1Brown Youtube Channel](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80461861",
   "metadata": {},
   "source": [
    "# Back of the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be9301",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = chapter_number\n",
    "t = np.linspace(0, (2*(n-1)+1)*np.pi/2, 1000)\n",
    "x = t*np.cos(t)**3\n",
    "y = 9*t*np.sqrt(np.abs(np.cos(t))) + t*np.sin(0.3*t)*np.cos(2*t)\n",
    "plt.plot(x, y, c=\"green\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'Chapter {chapter_number} took {int(end - start):d} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
