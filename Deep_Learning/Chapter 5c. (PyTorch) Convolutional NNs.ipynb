{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c766cd1",
   "metadata": {},
   "source": [
    "![Deep Learning for Scientists in a hurry](./fig/Title.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e01469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb1b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "chapter_number = 5\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd33b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6003af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a69e3",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9dc399",
   "metadata": {},
   "source": [
    "Until now we have to build Neural Networks where the deeper layers are connected densely to the outputs of the previous layer.\n",
    "\n",
    "When we were using the MNIST dataset, the $28 \\times 28$ grid of pixels were flattened to a single list of values.\n",
    "Doing that was good because it allow us to consider each pixel individually as a neuron and the network was in charge of the tasks of optimizing the weights that could identify digits correctly.\n",
    "\n",
    "However, the flattening also was unfortunate because we lost the natural idea of dealing with an image where there the pixels have a grid-like arrange in space. \n",
    "\n",
    "Convolutional Neural Networks have been very successfully used in applications with visual perceptual problems, being those images or even video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c57bb9",
   "metadata": {},
   "source": [
    "## The MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2300e010",
   "metadata": {},
   "source": [
    "The MNIST dataset contains $70,000$ images with handwritten single digits. The images are $28 \\times 28$ pixels. Pytorch sub package torchvision provides a method to download the MNIST dataset. The dataset must be downloaded in advance on a machine with internet access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e22155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6a07a",
   "metadata": {},
   "source": [
    "Let's check if the notebook is running on a machine with CUDA enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cde880",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data/',train=True,transform=transformation,download=False)\n",
    "test_dataset = datasets.MNIST('./data/',train=False,transform=transformation,download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4329105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897128ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33611c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_one(image):\n",
    "    image = image.numpy()[0]\n",
    "    plt.imshow(image,cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one(sample_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(sample_data):\n",
    "    images=sample_data[0]\n",
    "    fig, axs = plt.subplots(4, 8, sharex=True, sharey=True, figsize=(12,6))\n",
    "    for i in range(4):\n",
    "        for j in range(8):\n",
    "            axs[i,j].imshow(images[4*j+i].numpy()[0],cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e165664",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x,p=0.1, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f910ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "if is_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "data , target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cuda:\n",
    "    output = model(Variable(data.cuda()))\n",
    "else:\n",
    "    output = model(Variable(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd547e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , (data,target) in enumerate(data_loader):\n",
    "        if is_cuda:\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "        data , target = Variable(data,volatile),Variable(target)\n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        \n",
    "        running_loss += F.nll_loss(output,target,size_average=False).item()\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
    "    \n",
    "    loss_phrase=f\"{phase} loss : \".capitalize().ljust(19) \n",
    "    accuracy_phrase=f\"{phase} accuracy : \".capitalize().ljust(22)\n",
    "    \n",
    "    print(f'{loss_phrase} {loss:{5}.{2}}   {accuracy_phrase} {running_correct:{7}}/{len(data_loader.dataset)}{accuracy:{10}.{4}} %')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]\n",
    "for epoch in range(1,10):\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_loader,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_loader,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe03410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
    "plt.semilogy(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8204705",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'bo',label = 'train accuracy')\n",
    "plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'val accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0691e1",
   "metadata": {},
   "source": [
    "### 1D convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc95795",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(1,1,3,bias=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e97ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(1,1,7)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(Variable(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352c6965",
   "metadata": {},
   "source": [
    "### 1D Convolutions with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(1,1,3,padding=2,bias=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15485561",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(1,1,7)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa97b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(Variable(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e3b7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "There are many books about Deep Learning and many more on Machine Learning. \n",
    "This list is by no means an exhaustive list of books. I am listing the books from which I took inspiration. Also, I am listing materials where I found better ways to present topics. Often I am amazed by how people can create approachable materials for seemingly dry subjects.\n",
    "\n",
    "The order of the books goes from divulgation and practical to the more rigorous and mathematical. Slides, blogs, and videos are those I have found over the internet or suggested by others.\n",
    "\n",
    "### Selection of Books on Deep Learning\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Kelleher\" \n",
    "       src=\"./fig/books/Deep Learning - Kelleher.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      John D. Kelleher<br>\n",
    "      2019<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Charniak\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Charniak.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Eugene Charniak<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Skansi\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Skansi.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Sandro Skansi<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Subramanian\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Subramanian.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Vishnu Subramanian<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Stevens\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Stevens.png\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Eli Stevens, Luca Artiga and Thomas Viehmann<br>\n",
    "      2020<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with Python - Chollet\" \n",
    "       src=\"./fig/books/Deep Learning with Python - Chollet.jpg\" \n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with Python (Second Edition)<br>\n",
    "      Fran√ßois Chollet<br>\n",
    "      2021<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Patterson\" \n",
    "       src=\"./fig/books/Deep Learning - Patterson.jpeg\"\n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning, a practitioner's approach<br>\n",
    "      Josh Patterson and Adam Gibson<br>\n",
    "      2017<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Goodfellow\" \n",
    "       src=\"./fig/books/Deep Learning - Goodfellow.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      Ian Goodfellow, Yoshua Bengio, and Aaron Courville<br>\n",
    "      2016<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Interactive Books\n",
    "\n",
    "  * [Dive into Deep Learning](https://d2l.ai/index.html)<br>\n",
    "    Interactive deep learning book with code, math, and discussions<br> \n",
    "    Implemented with PyTorch, NumPy/MXNet, and TensorFlow<br>\n",
    "    Adopted at 300 universities from 55 countries\n",
    "\n",
    "\n",
    "### Slides\n",
    "\n",
    "  * John Urbanic's [\"Deep Learning in one Afternoon\"](https://www.psc.edu/wp-content/uploads/2022/04/Deep-Learning.pdf)<br>\n",
    "An excellent fast, condensed introduction to Deep Learning.<br>\n",
    "John is a Parallel Computing Scientist at Pittsburgh Supercomputing Center\n",
    "\n",
    "  * [Christopher Olah's Blog](http://colah.github.io) is very good. For example about [Back Propagation](http://colah.github.io/posts/2015-08-Backprop)\n",
    "\n",
    "  * Adam W. Harley on his CMU page offers [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://www.cs.cmu.edu/~aharley/vis/)\n",
    "\n",
    "\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    " * [Yale Digital Humanities Lab](https://github.com/YaleDHLab/lab-workshops)\n",
    " \n",
    " * Aurelien Geron Hands-on Machine Learning with Scikit-learn \n",
    "   [First Edition](https://github.com/ageron/handson-ml) and\n",
    "   [Second Edition](https://github.com/ageron/handson-ml2)\n",
    "   \n",
    " * [A progressive collection notebooks of the Machine Learning course by the University of Turin](https://github.com/rugantio/MachineLearningCourse)\n",
    "   \n",
    " * [A curated set of jupyter notebooks about many topics](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "   \n",
    "### Videos\n",
    "\n",
    " * [Caltech's \"Learning from Data\" by Professor Yaser Abu-Mostafa](https://work.caltech.edu/telecourse.html)\n",
    " \n",
    " * [3Blue1Brown Youtube Channel](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef53eb4c",
   "metadata": {},
   "source": [
    "# Back of the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c401c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = chapter_number\n",
    "t = np.linspace(0, (2*(n-1)+1)*np.pi/2, 1000)\n",
    "x = t*np.cos(t)**3\n",
    "y = 9*t*np.sqrt(np.abs(np.cos(t))) + t*np.sin(0.3*t)*np.cos(2*t)\n",
    "plt.plot(x, y, c=\"green\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f745acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'Chapter {chapter_number} took {int(end - start):d} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
