{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deep Learning for Scientists in a hurry](./fig/Title.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-08-09T15:21:28.591012-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.10\n",
      "IPython version      : 8.4.0\n",
      "\n",
      "Compiler    : GCC 9.4.0\n",
      "OS          : Linux\n",
      "Release     : 3.10.0-1160.24.1.el7.x86_64\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 24\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "chapter_number = 2\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet\n",
    "from mxnet import nd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.5.2\n",
      "numpy     : 1.19.1\n",
      "mxnet     : 1.9.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNet Multidimensional Arrays (NDArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache MXNet is deep learning software framework. Less well known than TensorFlow and PyTorch but offers some advantages for production systems and large scale trainins. Among the features highlighted we can mention:\n",
    "\n",
    "  * **Multiple languages**: \n",
    "  \n",
    "  MXNet supports frontend development on Python, R, Scala, Clojure, Julia, Perl, MATLAB and JavaScript, the back-end runs on C++.\n",
    "<br>\n",
    "\n",
    "  * **Scalability and Cloud Support**:\n",
    "\n",
    "    MXNet can be distributed on dynamic cloud infrastructure using a distributed parameter server. Multiple GPUs or CPUs help the framework to approach linear scale.\n",
    "\n",
    "    Several cloud computing services such as AWS and Azure offer support for MXNet.\n",
    "<br>\n",
    "\n",
    "  * **Flexible**:\n",
    "  \n",
    "    MXNet supports both imperative and symbolic programming. The framework allows developers to track, debug, save checkpoints, modify hyperparameters, and perform early stopping.\n",
    "<br>\n",
    "\n",
    "  * **Portable**:\n",
    "  \n",
    "    Supports an efficient deployment of a trained model to low-end devices for inference, such as mobile devices (using Amalgamation), Internet of things devices (using AWS Greengrass), serverless computing (using AWS Lambda) or containers. These low-end environments can have only weaker CPU or limited memory (RAM), and should be able to use the models that were trained on a higher-level environment (GPU based cluster, for example).\n",
    "<br>\n",
    "\n",
    "\n",
    "There are two main submodules:\n",
    "\n",
    "  * **NDArray**: Basic manipulation of multi dimensional arrays. This is a sort of replacement for Numpy\n",
    "  \n",
    "  * **Gluon**: The Actual Neural Network engine that uses NDArray for the operation.\n",
    "\n",
    "In this notebook we will concentrate on NDArray the MXNet data structure to work with multidimensional arrays on CPU and GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The NDArray  data structure\n",
    "\n",
    "In _MXNet_, `NDArray` is the core data structure for all mathematical\n",
    "computations.  Similar to NumPy, `NDArray` represents a multidimensional, fixed-size homogenous\n",
    "array.  If you're familiar with the scientific computing python package\n",
    "[NumPy](http://www.numpy.org/), you might notice that `mxnet.ndarray` is similar\n",
    "to `numpy.ndarray`.  \n",
    "\n",
    "Similar to other frameworks like TensorFlow and PyTorch, there are reason to create an alternative data structure that is capable of manipulate arrays allocated on GPU memory.\n",
    "MXNet's `NDArray` supports fast execution on a wide range of\n",
    "hardware configurations, including CPU, GPU, and multi-GPU machines. \n",
    "_MXNet_ NDArrays is that it also scales to distributed systems in the cloud.  \n",
    "\n",
    "Another advantage of MXNet's `NDArray` is the ability to execute code lazily.\n",
    "Lazy execution has the benefit of allowing it to automatically parallelize multiple operations across the available hardware.\n",
    "\n",
    "Same as NumPy ndarray, an `NDArray` is a multidimensional array of numbers with the same type.  We\n",
    "could represent the coordinates of a point in 3D space, e.g. `[2, 1, 6]` as a 1D\n",
    "array with shape (3).  Similarly, we could represent a 2D array.  Below, we\n",
    "present an array with length 2 along the first axis and length 3 along the\n",
    "second axis.\n",
    "```\n",
    "[[0, 1, 2]\n",
    " [3, 4, 5]]\n",
    "```\n",
    "Note that here the use of \"dimension\" is overloaded.  When we say a 2D array, we\n",
    "mean an array with 2 axes, not an array with two components.\n",
    "\n",
    "Each NDArray supports some important attributes that you'll often want to query:\n",
    "\n",
    "- **ndarray.shape**: The dimensions of the array. It is a tuple of integers\n",
    "  indicating the length of the array along each axis. For a matrix with `n` rows\n",
    "  and `m` columns, its `shape` will be `(n, m)`.\n",
    "- **ndarray.dtype**: A `numpy` _type_ object describing the type of its\n",
    "  elements.\n",
    "- **ndarray.size**: The total number of components in the array - equal to the\n",
    "  product of the components of its `shape`\n",
    "- **ndarray.context**: The device on which this array is stored, e.g. `cpu()` or\n",
    "  `gpu(1)`.\n",
    "\n",
    "\n",
    "A section of this tutorial uses GPUs. If you don't have GPUs on your\n",
    "machine, simply set the variable gpu_device (set in the GPUs section of this \n",
    "tutorial) to `mxnet.cpu()`.\n",
    "\n",
    "## Array Creation\n",
    "\n",
    "There are a few different ways to create an `NDArray`.\n",
    "\n",
    "* We can create an NDArray from a regular Python list or tuple by using the `array` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:23:09] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU\n"
     ]
    }
   ],
   "source": [
    "# create a 1-dimensional array with a python list\n",
    "a = nd.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2-dimensional array with a nested python list\n",
    "b = nd.array([[1,2,3], [2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a.shape': (3,), 'b.shape': (2, 3)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'a.shape':a.shape, 'b.shape':b.shape}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also create an MXNet NDArray from a `numpy.ndarray` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a.shape': (3, 5)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.arange(15).reshape(3,5)\n",
    "# create a 2-dimensional array from a numpy.ndarray object\n",
    "a = nd.array(c)\n",
    "{'a.shape':a.shape}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the element type with the option `dtype`, which accepts a numpy\n",
    "type. By default, `float32` is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float32 is used by default\n",
    "a = nd.array([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1 2 3]\n",
       "<NDArray 3 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an int32 array\n",
    "b = nd.array([1,2,3], dtype=np.int32)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.2 2.3]\n",
       "<NDArray 2 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 16-bit float array\n",
    "c = nd.array([1.2, 2.3], dtype=np.float16)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.float32, numpy.int32, numpy.float16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.dtype, b.dtype, c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know the size of the desired NDArray, but not the element values, MXNet\n",
    "offers several functions to create arrays with placeholder content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0.]\n",
       " [0. 0. 0.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 2-dimensional array full of zeros with shape (2,3)\n",
    "a = nd.zeros((2,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1.]\n",
       " [1. 1. 1.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a same shape array full of ones\n",
    "b = nd.ones((2,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[7. 7. 7.]\n",
       " [7. 7. 7.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a same shape array with all elements set to 7\n",
    "c = nd.full((2,3), 7)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1.148e-41 0.000e+00 7.511e-43]\n",
       " [0.000e+00 0.000e+00 0.000e+00]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a same shape whose initial content is random and\n",
    "# depends on the state of the memory\n",
    "d = nd.empty((2,3))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing Arrays\n",
    "\n",
    "When inspecting the contents of an `NDArray`, it's often convenient to first\n",
    "extract its contents as a `numpy.ndarray` using the `asnumpy` function.  Numpy\n",
    "uses the following layout:\n",
    "\n",
    "- The last axis is printed from left to right,\n",
    "- The second-to-last is printed from top to bottom,\n",
    "- The rest are also printed from top to bottom, with each slice separated from\n",
    "  the next by an empty line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.]],\n",
       "\n",
       "       [[ 6.,  7.,  8.],\n",
       "        [ 9., 10., 11.]],\n",
       "\n",
       "       [[12., 13., 14.],\n",
       "        [15., 16., 17.]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nd.arange(18).reshape((3,2,3))\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "\n",
    "When applied to NDArrays, the standard arithmetic operators apply *elementwise*\n",
    "calculations. The returned value is a new array whose content contains the\n",
    "result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[2. 2. 2.]\n",
       " [2. 2. 2.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((2,3))\n",
    "b = nd.ones((2,3))\n",
    "# elementwise plus\n",
    "c = a + b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-2. -2. -2.]\n",
       " [-2. -2. -2.]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise minus\n",
    "d = - c\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.7568025 -0.7568025]\n",
       " [-0.7568025 -0.7568025]\n",
       " [-0.7568025 -0.7568025]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise pow and sin, and then transpose\n",
    "e = nd.sin(c**2).T\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2.],\n",
       "       [2., 2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise max\n",
    "f = nd.maximum(a, c)\n",
    "f.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `NumPy`, `*` represents element-wise multiplication. For matrix-matrix\n",
    "multiplication, use `dot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.  3.]\n",
       " [ 6. 11.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.arange(4).reshape((2,2))\n",
    "b = a * a\n",
    "c = nd.dot(a,a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: [[0. 1.]\n",
      " [4. 9.]], \n",
      "\n",
      "c: [[ 2.  3.]\n",
      " [ 6. 11.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"b: %s, \\n\\nc: %s\" % (b.asnumpy(), c.asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment operators such as `+=` and `*=` modify arrays in place, and thus\n",
    "don't allocate new memory to create a new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((2,2))\n",
    "b = nd.ones(a.shape)\n",
    "b += a\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "The slice operator `[]` applies on axis 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 1.],\n",
       "       [4., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.array(np.arange(6).reshape(3,2))\n",
    "a[1:2] = 1\n",
    "a[:].asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice a particular axis with the method `slice_axis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [5.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = nd.slice_axis(a, axis=1, begin=1, end=2)\n",
    "d.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Manipulation\n",
    "\n",
    "Using `reshape`, we can manipulate any arrays shape as long as the size remains\n",
    "unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]],\n",
       "\n",
       "       [[12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.],\n",
       "        [20., 21., 22., 23.]]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.array(np.arange(24))\n",
    "b = a.reshape((2,3,4))\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `concat` method stacks multiple arrays along the first axis. Their\n",
    "shapes must be the same along the other axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 2., 2., 2.],\n",
       "       [1., 1., 1., 2., 2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((2,3))\n",
    "b = nd.ones((2,3))*2\n",
    "c = nd.concat(a,b)\n",
    "c.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce\n",
    "\n",
    "Some functions, like `sum` and `mean` reduce arrays to scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((2,3))\n",
    "b = nd.sum(a)\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also reduce an array along a particular axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nd.sum_axis(a, axis=1)\n",
    "c.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast\n",
    "\n",
    "We can also broadcast an array. Broadcasting operations, duplicate an array's\n",
    "value along an axis with length 1. The following code broadcasts along axis 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [5., 5., 5., 5.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.array(np.arange(6).reshape(6,1))\n",
    "b = a.broadcast_to((6,4))  #\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to simultaneously broadcast along multiple axes. In the following example, we broadcast along axes 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 1., 2.],\n",
       "         [0., 1., 2.]],\n",
       "\n",
       "        [[0., 1., 2.],\n",
       "         [0., 1., 2.]]],\n",
       "\n",
       "\n",
       "       [[[3., 4., 5.],\n",
       "         [3., 4., 5.]],\n",
       "\n",
       "        [[3., 4., 5.],\n",
       "         [3., 4., 5.]]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.reshape((2,1,1,3))\n",
    "d = c.broadcast_to((2,2,2,3))\n",
    "d.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting can be applied automatically when executing some operations,\n",
    "e.g. `*` and `+` on arrays of different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.],\n",
       "       [2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((3,2))\n",
    "b = nd.ones((1,2))\n",
    "c = a + b\n",
    "c.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copies\n",
    "\n",
    "When assigning an NDArray to another Python variable, we copy a reference to the\n",
    "*same* NDArray. However, we often need to make a copy of the data, so that we\n",
    "can manipulate the new array without overwriting the original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((2,2))\n",
    "b = a\n",
    "b is a # will be True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `copy` method makes a deep copy of the array and its data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.copy()\n",
    "b is a  # will be False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code allocates a new NDArray and then assigns to *b*. When we do not\n",
    "want to allocate additional memory, we can use the `copyto` method or the slice\n",
    "operator `[]` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nd.ones(a.shape)\n",
    "c = b\n",
    "c[:] = a\n",
    "d = b\n",
    "a.copyto(d)\n",
    "(c is b, d is b)  # Both will be True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics\n",
    "\n",
    "MXNet's NDArray offers some advanced features that differentiate it from the\n",
    "offerings you'll find in most other libraries.\n",
    "\n",
    "### GPU Support\n",
    "\n",
    "By default, NDArray operators are executed on CPU. But with MXNet, it's easy to\n",
    "switch to another computation resource, such as GPU, when available. Each\n",
    "NDArray's device information is stored in `ndarray.context`. When MXNet is\n",
    "compiled with flag `USE_CUDA=1` and the machine has at least one NVIDIA GPU, we\n",
    "can cause all computations to run on GPU 0 by using context `mxnet.gpu(0)`, or\n",
    "simply `mxnet.gpu()`. When we have access to two or more GPUs, the 2nd GPU is\n",
    "represented by `mxnet.gpu(1)`, etc.\n",
    "\n",
    "**Note** In order to execute the following section on a cpu set gpu_device to mxnet.cpu()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_device(gpu_number=0):\n",
    "    try:\n",
    "        _ = mxnet.nd.array([1, 2, 3], ctx=mxnet.gpu(gpu_number))\n",
    "    except mxnet.MXNetError:\n",
    "        return None\n",
    "    return mxnet.gpu(gpu_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:27:14] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gpu(0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if gpu_device() is None:\n",
    "    my_device=mxnet.cpu()\n",
    "else:\n",
    "    my_device=mxnet.gpu()\n",
    "    \n",
    "my_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " ...\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]]\n",
      "<NDArray 100x100 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    a = nd.ones((100,100))\n",
    "    b = nd.ones((100,100))\n",
    "    c = a + b\n",
    "    print(c)\n",
    "# in default mx.cpu() is used\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " ...\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [2. 2. 2. ... 2. 2. 2.]]\n",
      "<NDArray 100x100 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# change the default context to the first GPU\n",
    "with mxnet.Context(my_device):\n",
    "    f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explicitly specify the context when creating an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " ...\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]]\n",
       "<NDArray 100x100 @gpu(0)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((100, 100), my_device)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, MXNet requires two arrays to sit on the same device for\n",
    "computation. There are several methods for copying data between devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': \n",
       " [[2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  ...\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]]\n",
       " <NDArray 100x100 @gpu(0)>,\n",
       " 'e': \n",
       " [[2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  ...\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]\n",
       "  [2. 2. 2. ... 2. 2. 2.]]\n",
       " <NDArray 100x100 @gpu(0)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((100,100), mxnet.cpu())\n",
    "b = nd.ones((100,100), my_device)\n",
    "c = nd.ones((100,100), my_device)\n",
    "a.copyto(c)  # copy from CPU to GPU\n",
    "d = b + c\n",
    "e = b.as_in_context(c.context) + c  # same to above\n",
    "{'d':d, 'e':e}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize From/To (Distributed) Filesystems\n",
    "\n",
    "MXNet offers two simple ways to save (load) data to (from) disk. The first way\n",
    "is to use `pickle`, as you might with any other Python objects. `NDArray` is\n",
    "pickle-compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "a = nd.ones((2, 3))\n",
    "# pack and then dump into disk\n",
    "data = pkl.dumps(a)\n",
    "pkl.dump(data, open('tmp.pickle', 'wb'))\n",
    "# load from disk and then unpack\n",
    "data = pkl.load(open('tmp.pickle', 'rb'))\n",
    "b = pkl.loads(data)\n",
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way is to directly dump to disk in binary format by using the `save`\n",
    "and `load` methods. We can save/load a single NDArray, or a list of NDArrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[1. 1. 1.]\n",
       "  [1. 1. 1.]]\n",
       " <NDArray 2x3 @cpu(0)>,\n",
       " \n",
       " [[1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]]\n",
       " <NDArray 5x6 @cpu(0)>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.ones((2,3))\n",
    "b = nd.ones((5,6))\n",
    "nd.save(\"temp.ndarray\", [a,b])\n",
    "c = nd.load(\"temp.ndarray\")\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to save or load a dict of NDArrays in this fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': \n",
       " [[1. 1. 1.]\n",
       "  [1. 1. 1.]]\n",
       " <NDArray 2x3 @cpu(0)>,\n",
       " 'b': \n",
       " [[1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]\n",
       "  [1. 1. 1. 1. 1. 1.]]\n",
       " <NDArray 5x6 @cpu(0)>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a':a, 'b':b}\n",
    "nd.save(\"./output/temp.ndarray\", d)\n",
    "c = nd.load(\"./output/temp.ndarray\")\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load` and `save` methods are preferable to pickle in two respects\n",
    "\n",
    "1. When using these methods, you can save data from within the Python interface\n",
    "   and then use it later from another language's binding. For example, if we save\n",
    "   the data in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nd.ones((2, 3))\n",
    "nd.save(\"./output/temp.ndarray\", [a,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can later load it from R:\n",
    "```\n",
    "a <- mx.nd.load(\"temp.ndarray\")\n",
    "as.array(a[[1]])\n",
    "##      [,1] [,2] [,3]\n",
    "## [1,]    1    1    1\n",
    "## [2,]    1    1    1\n",
    "```\n",
    "\n",
    "2. When a distributed filesystem such as Amazon S3 or Hadoop HDFS is set up, we\n",
    "   can directly save to and load from it.\n",
    "\n",
    "```\n",
    "mx.nd.save('s3://mybucket/mydata.ndarray', [a,])  # if compiled with USE_S3=1\n",
    "mx.nd.save('hdfs///users/myname/mydata.bin', [a,])  # if compiled with USE_HDFS=1\n",
    "```\n",
    "\n",
    "### Lazy Evaluation and Automatic Parallelization\n",
    "\n",
    "MXNet uses lazy evaluation to achieve superior performance.  When we run `a=b+1`\n",
    "in Python, the Python thread just pushes this operation into the backend engine\n",
    "and then returns.  There are two benefits to this approach:\n",
    "\n",
    "1. The main Python thread can continue to execute other computations once the\n",
    "   previous one is pushed. It is useful for frontend languages with heavy\n",
    "   overheads.\n",
    "2. It is easier for the backend engine to explore further optimization, such as\n",
    "   auto parallelization.\n",
    "\n",
    "The backend engine can resolve data dependencies and schedule the computations\n",
    "correctly. It is transparent to frontend users. We can explicitly call the\n",
    "method `wait_to_read` on the result array to wait until the computation\n",
    "finishes. Operations that copy data from an array to other packages, such as\n",
    "`asnumpy`, will implicitly call `wait_to_read`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for all computations are pushed into the backend engine:\n",
      " 0.001362 sec\n",
      "time for all computations are finished:\n",
      " 0.255941 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def do(x, n):\n",
    "    \"\"\"push computation into the backend engine\"\"\"\n",
    "    return [nd.dot(x,x) for i in range(n)]\n",
    "def wait(x):\n",
    "    \"\"\"wait until all results are available\"\"\"\n",
    "    for y in x:\n",
    "        y.wait_to_read()\n",
    "\n",
    "tic = time.time()\n",
    "a = nd.ones((1000,1000))\n",
    "b = do(a, 50)\n",
    "print('time for all computations are pushed into the backend engine:\\n %f sec' % (time.time() - tic))\n",
    "wait(b)\n",
    "print('time for all computations are finished:\\n %f sec' % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides analyzing data read and write dependencies, the backend engine is able\n",
    "to schedule computations with no dependency in parallel. For example, in the\n",
    "following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nd.ones((2,3))\n",
    "b = a + 1\n",
    "c = a + 2\n",
    "d = b * c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the second and third lines can be executed in parallel. The following example\n",
    "first runs on CPU and then on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "a = nd.ones((1000,1000))\n",
    "b = nd.ones((3000,3000), my_device)\n",
    "tic = time.time()\n",
    "c = do(a, n)\n",
    "wait(c)\n",
    "print('Time to finish the CPU workload: %f sec' % (time.time() - tic))\n",
    "d = do(b, n)\n",
    "wait(d)\n",
    "print('Time to finish both CPU/GPU workloads: %f sec' % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we issue all workloads at the same time. The backend engine will try to\n",
    "parallel the CPU and GPU computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "c = do(a, n)\n",
    "d = do(b, n)\n",
    "wait(c)\n",
    "wait(d)\n",
    "print('Both as finished in: %f sec' % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# References\n",
    "\n",
    "There are many books about Deep Learning and many more on Machine Learning. \n",
    "This list is by no means an exhaustive list of books. I am listing the books from which I took inspiration. Also, I am listing materials where I found better ways to present topics. Often I am amazed by how people can create approachable materials for seemingly dry subjects.\n",
    "\n",
    "The order of the books goes from divulgation and practical to the more rigorous and mathematical. Slides, blogs, and videos are those I have found over the internet or suggested by others.\n",
    "\n",
    "### Selection of Books on Deep Learning\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Kelleher\" \n",
    "       src=\"./fig/books/Deep Learning - Kelleher.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      John D. Kelleher<br>\n",
    "      2019<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Charniak\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Charniak.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Eugene Charniak<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Introduction to Deep Learning - Skansi\" \n",
    "       src=\"./fig/books/Introduction to Deep Learning - Skansi.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Introduction to Deep Learning<br>\n",
    "      Sandro Skansi<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Subramanian\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Subramanian.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Vishnu Subramanian<br>\n",
    "      2018<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with PyTorch - Stevens\" \n",
    "       src=\"./fig/books/Deep Learning with PyTorch - Stevens.png\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with PyTorch<br>\n",
    "      Eli Stevens, Luca Artiga and Thomas Viehmann<br>\n",
    "      2020<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning with Python - Chollet\" \n",
    "       src=\"./fig/books/Deep Learning with Python - Chollet.jpg\" \n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning with Python (Second Edition)<br>\n",
    "      Fran√ßois Chollet<br>\n",
    "      2021<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Patterson\" \n",
    "       src=\"./fig/books/Deep Learning - Patterson.jpeg\"\n",
    "       height=\"100\" width=\"100\" />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning, a practitioner's approach<br>\n",
    "      Josh Patterson and Adam Gibson<br>\n",
    "      2017<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"border: none; float: left; width: 200; padding: 5px\">\n",
    "  <img alt=\"Deep Learning - Goodfellow\" \n",
    "       src=\"./fig/books/Deep Learning - Goodfellow.jpg\" \n",
    "       height=\"100\" width=\"100\"  />\n",
    "  </div>\n",
    "  <div style=\"border: none; float: left; width: 800; padding: 5px\">\n",
    "      Deep Learning<br>\n",
    "      Ian Goodfelow, Yoshua Bengio, and Aaron Courville<br>\n",
    "      2016<br>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "### Interactive Books\n",
    "\n",
    "  * [Dive into Deep Learning](https://d2l.ai/index.html)<br>\n",
    "    Interactive deep learning book with code, math, and discussions<br> \n",
    "    Implemented with PyTorch, NumPy/MXNet, and TensorFlow<br>\n",
    "    Adopted at 300 universities from 55 countries\n",
    "\n",
    "\n",
    "### Slides\n",
    "\n",
    "  * John Urbanic's [\"Deep Learning in one Afternoon\"](https://www.psc.edu/wp-content/uploads/2022/04/Deep-Learning.pdf)<br>\n",
    "An excellent fast, condensed introduction to Deep Learning.<br>\n",
    "John is a Parallel Computing Scientist at Pittsburgh Supercomputing Center\n",
    "\n",
    "  * [Christopher Olah's Blog](http://colah.github.io) is very good. For example about [Back Propagation](http://colah.github.io/posts/2015-08-Backprop)\n",
    "\n",
    "  * Adam W. Harley on his CMU page offers [An Interactive Node-Link Visualization of Convolutional Neural Networks](https://www.cs.cmu.edu/~aharley/vis/)\n",
    "\n",
    "\n",
    "\n",
    "### Jupyter Notebooks\n",
    "\n",
    " * [Yale Digital Humanities Lab](https://github.com/YaleDHLab/lab-workshops)\n",
    " \n",
    " * Aurelein Geron Hands-on Machine Learning with Scikit-learn \n",
    "   [First Edition](https://github.com/ageron/handson-ml) and\n",
    "   [Second Edition](https://github.com/ageron/handson-ml2)\n",
    "   \n",
    " * [A progressive collection notebooks of the Machine Learning course by the University of Turin](https://github.com/rugantio/MachineLearningCourse)\n",
    "   \n",
    " * [A curated set of jupyter notebooks about many topics](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "   \n",
    "### Videos\n",
    "\n",
    " * [Caltech's \"Learning from Data\" by Professor Yaser Abu-Mostafa](https://work.caltech.edu/telecourse.html)\n",
    " \n",
    " * [3Blue1Brown Youtube Channel](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back of the Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = chapter_number\n",
    "t = np.linspace(0, (2*(n-1)+1)*np.pi/2, 1000)\n",
    "x = t*np.cos(t)**3\n",
    "y = 9*t*np.sqrt(np.abs(np.cos(t))) + t*np.sin(0.3*t)*np.cos(2*t)\n",
    "plt.plot(x, y, c=\"green\")\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'Chapter {chapter_number} took {int(end - start):d} seconds')"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
